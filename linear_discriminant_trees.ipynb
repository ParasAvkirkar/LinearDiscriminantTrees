{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "iris_column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']\n",
    "utils = Utils()\n",
    "dataset = utils.load_dataset('data/iris.data', cols=iris_column_names)\n",
    "X = dataset.iloc[:,:-1]\n",
    "y = dataset.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Utils:\n",
    "    def load_dataset(self, path, cols):\n",
    "        df = pd.read_csv(path, names=cols)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(X1, X2):\n",
    "    X1, X2 = np.array(X1), np.array(X2)\n",
    "\n",
    "    return np.sqrt(np.sum(np.square(X1 - X2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TreeNode():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.val = None\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        \n",
    "    def __init__(self, lda, left, right):\n",
    "        self.val = lda\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        \n",
    "    def __init__(self, label):\n",
    "        self.val = label\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        \n",
    "    def is_leaf(self):\n",
    "        return self.left is None and self.right is None\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelDetails:\n",
    "    def __init__(self, X, y, label):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.label = label\n",
    "        self.compute_means()\n",
    "        self.sample_count = X.shape[0]\n",
    "        \n",
    "    def compute_means(self):\n",
    "        self.mean = self.X.describe().loc['mean'].values.reshape(-1,1)\n",
    "        \n",
    "    def get_values(self):\n",
    "        return self.X.values\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        \"\"\"Overrides the default implementation\"\"\"\n",
    "        if isinstance(other, LabelDetails):\n",
    "            return self.label == other.label and (self.mean == other.mean).all()\n",
    "        return False\n",
    "    \n",
    "    def __ne__(self, other):\n",
    "        ret = not self.__eq__(other)\n",
    "        return ret\n",
    "        \n",
    "    def __str__(self):\n",
    "        str_ = \"Class details: \"\n",
    "        str_ += \" - means:\"+str(self.mean) + \"\\n\"\n",
    "        str_ += \" - class_name:\"+self.label + \"\\n\"\n",
    "        str_ += \" - num_instances:\"+str(self.samples)\n",
    "        return str_\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        # Initialize class parameters\n",
    "        self.root = TreeNode()\n",
    "        self.distance_fn = Utils().euclidean_distance\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Function to train a decision tree for the given training data X\n",
    "        label_details = self.create_labels(X, y)\n",
    "        self.root = self.build_tree(label_details)\n",
    "        print(str(label_details))\n",
    "        \n",
    "    def predict(self, test_sample):\n",
    "        # Function to classify test data\n",
    "        pass\n",
    "    \n",
    "    def build_linear_discriminant(self, left_split, right_split):\n",
    "        features = None\n",
    "\n",
    "        for label_detail in left_split:\n",
    "            if features is None:\n",
    "                features = label_detail.get_values()\n",
    "                labels = np.zeros(features.shape[0]) # 0.0.0.0\n",
    "            else:\n",
    "                features = np.append(features, label_detail.get_values())\n",
    "                labels = np.append(labels, np.zeros(features.shape[0]))\n",
    "\n",
    "        for label_detail in right_split:\n",
    "            if features is None:\n",
    "                features = label_detail.get_values()\n",
    "                labels = np.ones(features.shape[0]) # 1.1.1.1.\n",
    "            else:\n",
    "                features = np.append(features, label_detail.get_values())\n",
    "                labels = np.append(labels, np.ones(features.shape[0]))\n",
    "\n",
    "        return LDA().fit(features, labels)\n",
    "        \n",
    "    \n",
    "    def build_tree(self, label_details):\n",
    "        if len(label_details) == 1:\n",
    "            # create leaf node\n",
    "            leaf_node = TreeNode(label_details[0].label)\n",
    "            return leaf_node\n",
    "        \n",
    "        left_split, right_split = self.heuristic_split(label_details)\n",
    "        left_split, right_split = self.exchange(left_split, right_split, label_details)\n",
    "        \n",
    "        left_node, right_node = self.build_tree(left_split), self.build_tree(right_split)\n",
    "        lda_model = self.build_linear_discriminant(left_split, right_split)\n",
    "        \n",
    "        return TreeNode(lda_model, left_node, right_node)\n",
    "\n",
    "    \n",
    "    def heuristic_split(self, label_details):\n",
    "        maximum_distance = float('-inf')\n",
    "        splits = {}\n",
    "        for i in range(len(label_details)):\n",
    "            for j in range(i, len(label_details)):\n",
    "                distance = euclidean_distance(label_details[i].mean, label_details[j].mean)\n",
    "                if distance > maximum_distance:\n",
    "                    maximum_distance = distance\n",
    "                    splits = {'left': [label_details[i]], 'right': [label_details[j]]}\n",
    "        maximum_distance_splits = splits['left'] + splits['right']\n",
    "        for label_detail in label_details:\n",
    "            if label_detail not in maximum_distance_splits:\n",
    "                left_distance = euclidean_distance(label_detail.mean, splits['left'][0].mean)\n",
    "                right_distance = euclidean_distance(label_detail.mean, splits['right'][0].mean)\n",
    "                if left_distance < right_distance:\n",
    "                    splits['left'].append(label_detail)\n",
    "                else:\n",
    "                    splits['right'].append(label_detail)\n",
    "                    \n",
    "        return splits['left'], splits['right']\n",
    "    \n",
    "        \n",
    "    def exchange(self, left_split, right_split, label_details):\n",
    "        maximum_information_gain = self.compute_information_gain(left_split, right_split)\n",
    "        best_partition = (left_split, right_split)\n",
    "        for label_detail in label_details:\n",
    "            left_split_copy = left_split.copy()\n",
    "            right_split_copy = right_split.copy()\n",
    "            \n",
    "            # equals()\n",
    "            if label_detail in left_split:\n",
    "                left_split_copy = [o for o in left_split_copy if o != label_detail]\n",
    "                right_split_copy.append(label_detail)\n",
    "            else:\n",
    "                right_split_copy = [o for o in right_split_copy if o != label_detail]\n",
    "                left_split_copy.append(label_detail)\n",
    "        \n",
    "            if len(left_split_copy) == 0 or len(right_split_copy) == 0:\n",
    "                continue\n",
    "        \n",
    "            information_gain = self.compute_information_gain(left_split_copy, right_split_copy)\n",
    "        \n",
    "            if information_gain > maximum_information_gain:\n",
    "                maximum_information_gain = information_gain\n",
    "                best_partition = (left_split_copy, right_split_copy)\n",
    "\n",
    "        # TODO: remove this\n",
    "        assert(len(best_partition[0]) + len(best_partition[1]) == len(left_split) + len(right_split))\n",
    "        return best_partition \n",
    "        \n",
    "    \n",
    "    def compute_information_gain(self, left_split, right_split):\n",
    "        if len(left_split) == 0 or len(right_split) == 0:\n",
    "            return float('-inf')\n",
    "        \n",
    "        lda_model = self.build_linear_discriminant(left_split, right_split)\n",
    "        \n",
    "        total_left_samples = sum([ld.sample_count for ld in left_split])\n",
    "        total_right_samples = sum([rd.sample_count for rd in right_split])\n",
    "        total = total_left_samples + total_right_samples\n",
    "#         print(str(total) + \" \" + str(total_right_samples) + \" \" + str(total_left_samples))\n",
    "\n",
    "        e0 = 0.0\n",
    "        information_gain = 0.0\n",
    "        for detail in left_split + right_split:\n",
    "            e0 = e0 + self.compute_entropy(detail.sample_count, total)\n",
    "        \n",
    "        left_predictions = []\n",
    "        right_predictions = []\n",
    "        \n",
    "        for split in [left_split, right_split]:\n",
    "            l, r = self.get_lda_predictions(split, lda)\n",
    "            left_predictions = left_predictions + l\n",
    "            right_predictions = right_predictions + r\n",
    "            \n",
    "        \n",
    "        information_gain = e0\n",
    "        for predictions, total_count in [(left_predictions, total_left_samples), (right_predictions, total_right_samples)]:\n",
    "            val = 0.0\n",
    "            for prediction in predictions:\n",
    "                if prediction != 0.0:\n",
    "                    temp = float(prediction)/total_count\n",
    "                    val = val + temp * np.log2(temp)\n",
    "            information_gain += val * total_count/total\n",
    "        \n",
    "        return information_gain\n",
    "    \n",
    "        \n",
    "    def compute_entropy(self, prediction, total):\n",
    "        val = float(prediction)/total\n",
    "        return -1.0 * (val) * np.log2(val)\n",
    "            \n",
    "        \n",
    "    def get_lda_predictions(split, lda):\n",
    "        left_predictions = []\n",
    "        right_predictions = []\n",
    "        for label_detail in split:\n",
    "            left_count = 0\n",
    "            right_count = 0\n",
    "            rows = label_detail.X.shape[0]\n",
    "            X = label_detail.X.values\n",
    "            for i in range(rows):\n",
    "                if lda.predict([ X[i] ]) == 0:\n",
    "                    left_count += 1\n",
    "                else:\n",
    "                    right_count += 1\n",
    "            \n",
    "            left_predictions.append(left_count)\n",
    "            right_predictions.append(right_count)\n",
    "            \n",
    "        return left_predictions, right_predictions\n",
    "        \n",
    "    \n",
    "    def create_labels(self, X, y):\n",
    "        unique_classes = set(y.unique())\n",
    "        label_details = []\n",
    "        for class_type in unique_classes:\n",
    "            yi = y[y==class_type]\n",
    "            indexes = yi.index\n",
    "            xi = X.iloc[indexes]\n",
    "            label_detail = LabelDetails(xi, yi, class_type)\n",
    "            \n",
    "            label_details.append(label_detail)\n",
    "        \n",
    "        return label_details\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Driver:\n",
    "    def main(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Class details:  - means:[[5.936]\\n [2.77 ]\\n [4.26 ]\\n [1.326]]\\n - class_name:Iris-versicolor\\n - num_instances:50',\n",
       " 'Class details:  - means:[[6.588]\\n [2.974]\\n [5.552]\\n [2.026]]\\n - class_name:Iris-virginica\\n - num_instances:50',\n",
       " 'Class details:  - means:[[5.006]\\n [3.418]\\n [1.464]\\n [0.244]]\\n - class_name:Iris-setosa\\n - num_instances:50']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model()\n",
    "ret = model.fit(X, y)\n",
    "[str(r) for r in ret]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(dataset, dataset['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset['class']\n",
    "indexes = y[y=='Iris-setosa'].index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = X.iloc[indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "reshape() takes exactly 1 argument (0 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-5e672dd4276c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: reshape() takes exactly 1 argument (0 given)"
     ]
    }
   ],
   "source": [
    "t.describe().loc['mean'].values.reshape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
